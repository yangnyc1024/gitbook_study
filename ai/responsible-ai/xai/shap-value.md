# SHAP value

## What is SHAP value?

We are interested in understanding how each feature contributes to a prediction. In linear models, this is relatively straightforward to compute. Consider a linear model:

$$
\hat{f}(x) = \beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p
$$

where $$x$$ is the input instance we want to explain, each $$x_j$$ for ( $$j = 1, \ldots, p$$ ) is the feature value, and ( $$\beta_j$$ ) is the coefficient corresponding to feature $$j$$.

The contribution of the $$j$$-th feature to the prediction ( $$\hat{f}(x)$$ ) is defined as:

$$
\phi_j = \beta_j x_j - \mathbb{E}(\beta_j X_j) = \beta_j x_j - \beta_j \mathbb{E}(X_j)
$$

Here, ( $$\mathbb{E}(\beta_j X_j$$) denotes the average contribution of the $$j$$-th feature. The contribution measures how much **this feature deviates from its average impact**. If we sum the contributions of all features for a given instance, we obtain:

$$
\sum_{j=1}^p \phi_j = \sum_{j=1}^p (\beta_j x_j - \mathbb{E}(\beta_j X_j)) \\
= \left( \beta_0 + \sum_{j=1}^p \beta_j x_j \right) - \left( \beta_0 + \sum_{j=1}^p \mathbb{E}(\beta_j X_j) \right) \\
= \hat{f}(x) - \mathbb{E}(f(X))
$$

In other words, the total contribution of input $$x$$ is equal to the prediction minus the average prediction. Since we often work with non-linear models (e.g., ensemble methods), we require a more general approach. We adopt the **Shapley value** from cooperative game theory to attribute the prediction of any machine learning model to individual feature contributions.

The Shapley value of feature $$j$$ for an instance is defined as:

$$
\phi_j(val) = \sum_{S \subseteq \{x_1, \ldots, x_p\} \setminus \{x_j\}} \frac{|S|!(p - |S| - 1)!}{p!} \left[ val(S \cup \{x_j\}) - val(S) \right]
$$

Here:

* $$S$$ is a subset of the full set of features (a _coalition_),
* $$x$$ is the feature vector of the instance being explained,
* $$p$$is the total number of features,
* $$\frac{|S|!(p - |S| - 1)!}{p!}$$ is the Shapley weight for subset ( S ),
* $$val(S)$$ is the value function (i.e., model output) for feature subset $$S$$, marginalized over the features not in $$S$$. The value function $$val_x(S)$$ is computed as:

$$
val_x(S) = \int f(x_1, \ldots, x_p) \, dP_{x_{\notin S}} - \mathbb{E}_X[\hat{f}(X)]
$$

* **This expression marginalizes over the features** not included in $$S$$. For example, suppose the model uses 4 features $$x_1, x_2, x_3, x_4$$, and we consider the coalition $$S = {x_1, x_3}$$. Then the value function is:

$$
val_x(S) = \int_{\mathbb{R}} \int_{\mathbb{R}} f(x_1, X_2, x_3, X_4) \, dP_{X_2, X_4} - \mathbb{E}_X[\hat{f}(X)]
$$





## What is baseline?

åœ¨ TreeSHAP ä¸­ï¼Œbaselineï¼ˆæœ‰æ—¶ä¹Ÿå« **expected value**ï¼‰æ˜¯ï¼š

> **æ¨¡å‹åœ¨è®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸Šæ‰€æœ‰é¢„æµ‹å€¼çš„å¹³å‡å€¼**ï¼Œå³\
> $$baseline=E[f(x)]$$

* å¯¹äºå›å½’é—®é¢˜ï¼šå°±æ˜¯æ‰€æœ‰æ ·æœ¬é¢„æµ‹å€¼çš„å¹³å‡å€¼ã€‚
* å¯¹äºäºŒåˆ†ç±»ï¼ˆlog-odds æ¨¡å‹ï¼‰ï¼šæ˜¯ logit è¾“å‡ºçš„å¹³å‡å€¼ã€‚
* å¯¹äºæ¦‚ç‡è¾“å‡ºï¼ˆç»è¿‡ sigmoidï¼‰æ¨¡å‹ï¼šå¯ä»¥å–å¹³å‡æ¦‚ç‡ä½œä¸º baselineï¼ˆä½† TreeSHAP é»˜è®¤æ˜¯åœ¨ log-odds ä¸Šè®¡ç®—ï¼‰ã€‚



## What is the SHAP additive?

**SHAP æ˜¯åŠ æ€§çš„ï¼Œä½†ä¸ä»£è¡¨æ¨¡å‹æ˜¯çº¿æ€§çš„**

SHAP çš„æ ¸å¿ƒæ•°å­¦åŸºç¡€æ˜¯ **Shapley value**ï¼Œæ»¡è¶³ä»¥ä¸‹å±æ€§ï¼š

> å¯¹äºä»»æ„æ¨¡å‹ $$f(x)$$ï¼Œæˆ‘ä»¬å¯ä»¥å†™æˆï¼š
>
> $$f(x) = \phi_0 + \sum_{i = 1}^M \phi_i$$
>
> å…¶ä¸­ï¼š
>
> * $$\phi_0$$â€‹ æ˜¯ baselineï¼ˆå³ $$\mathbb{E}[f(x)]$$ï¼‰
> * $$\phi_i$$â€‹ æ˜¯ç¬¬ $$i$$ ä¸ªç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„è¾¹é™…è´¡çŒ®ï¼ˆSHAP å€¼ï¼‰

## SHAP value  VS linear coefficient

* åœ¨çº¿æ€§æ¨¡å‹ä¸­ï¼Œ**ç³»æ•°** $$\beta$$ **æ˜¯æ¨¡å‹æœ¬èº«å­¦å‡ºæ¥çš„å‚æ•°**ã€‚
  * å®ƒåæ˜ çš„æ˜¯**æ¯ä¸ªç‰¹å¾å•ä½å˜åŒ–**å¯¹è¾“å‡ºçš„ç›´æ¥å½±å“ã€‚
  * å’Œç‰¹å¾æ ‡å‡†åŒ–ã€ç¼©æ”¾ã€å…±çº¿æ€§å¯†åˆ‡ç›¸å…³ã€‚
* åœ¨ SHAP ä¸­ï¼Œ$$\phi$$ **æ˜¯æ¨¡å‹é¢„æµ‹åè®¡ç®—å‡ºæ¥çš„å½’å› å€¼ã€‚**
  * å®ƒä¸æ˜¯æ¨¡å‹çš„å‚æ•°ï¼Œè€Œæ˜¯è§£é‡Šæ¨¡å‹é¢„æµ‹çš„â€œåˆ†æ‘Šç»“æœâ€ã€‚
  * ä¼šéšç€ç‰¹å¾å€¼ã€æ ·æœ¬ã€æ¨¡å‹ç»“æ„ã€ç”šè‡³ç‰¹å¾é¡ºåºè€Œå˜åŒ–ã€‚



#### å‡è®¾ä½ æœ‰ä¸€ä¸ªæ¨¡å‹é¢„æµ‹ï¼š

**ğŸ’¡ çº¿æ€§æ¨¡å‹ï¼š**

$$\text{premium} = \beta_0 + 0.8 \cdot \text{age} + 2.5 \cdot \text{claim\_count}$$

* ä¸è®ºæ ·æœ¬æ˜¯å¹´è½»è¿˜æ˜¯å¹´è€ï¼Œ`age` çš„å•ä½è´¡çŒ®æ°¸è¿œæ˜¯æ¯å¤šä¸€å² â†’ ä¿è´¹æ¶¨ 0.8 å…ƒã€‚
* æ¨¡å‹ç»“æ„æ˜¯â€œå…¨å±€ä¸€è‡´çš„â€ã€‚

**ğŸ’¡ éçº¿æ€§æ¨¡å‹ï¼ˆå¦‚ XGBoostï¼‰+ SHAPï¼š**

* å¯¹å¹´è½»äººï¼Œ`age` çš„ SHAP å€¼å¯èƒ½æ˜¯ -1.0 â†’ é™ä½ä¿è´¹ï¼›
* å¯¹å¹´é•¿çš„äººï¼Œ`age` çš„ SHAP å€¼å¯èƒ½æ˜¯ +3.0 â†’ æé«˜ä¿è´¹ï¼›
* è¯´æ˜æ¨¡å‹å¯¹ `age` çš„ä½¿ç”¨æ˜¯éçº¿æ€§ã€æœ‰é˜ˆå€¼çš„ï¼ˆæ¯”å¦‚ 60 å²ä»¥ä¸Šé£é™©å˜å¤§ï¼‰ã€‚

<figure><img src="../../.gitbook/assets/Screenshot 2025-03-24 at 4.03.48â€¯PM.png" alt=""><figcaption></figcaption></figure>



## Extra

* mean SHAP value ä¸ç­‰åŒäºçº¿æ€§æ¨¡å‹ä¸­çš„ç³»æ•°æˆ–è´¡çŒ®ï¼Œå®ƒæ˜¯å¯¹ç‰¹å¾åœ¨æ•´ä¸ªæ ·æœ¬ç©ºé—´ä¸­è¾¹é™…è´¡çŒ®çš„å¹³å‡ä¼°è®¡ã€‚è™½ç„¶ SHAP decomposition åœ¨å½¢å¼ä¸Šæ˜¯åŠ æ€§çš„ï¼Œä½†å®ƒèƒ½æ•æ‰æ¨¡å‹ä¸­å¤æ‚çš„éçº¿æ€§å’Œç‰¹å¾äº¤äº’ï¼Œä»è€Œä¸ºä»»æ„æ¨¡å‹æä¾›ä¸€è‡´çš„è§£é‡Šã€‚
* The **mean SHAP value** reflects the featureâ€™s **average marginal contribution** to the model output across all data points. A decrease in this value suggests that the model is now **less reliant on this feature** and **more dependent on other variables** to explain the predictions.\
  However, this does **not imply a consistent 15% contribution** as would be the case in a linear model with fixed coefficients. For example, the SHAP value of a feature could account for 10% of the prediction in one data point, and 25% in another â€” highlighting the **local, context-specific nature** of SHAP-based explanations.



Reference

* [https://christophm.github.io/interpretable-ml-book/shap.html](https://christophm.github.io/interpretable-ml-book/shap.html)&#x20;
* [https://zhuanlan.zhihu.com/p/85791430](https://zhuanlan.zhihu.com/p/85791430)
