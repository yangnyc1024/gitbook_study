# Basic RNN





#### Review

* 我们介绍了$$n$$元语法模型， 其中单词$$x_t$$在时间步$$t$$的条件概率仅取决于前面$$n-1$$个单词。 对于时间步$$t-(n-1)$$之前的单词， 如果我们想将其可能产生的影响合并到$$x_t$$上， 需要增加$$�$$，然而模型参数的数量也会随之呈指数增长， 因为词表$$|\mathcal{V}|$$需要存储$$|\mathcal{V}|^n$$个数字，&#x20;
* 因此与其将$$P(x_t | x_{t-1}, \cdots, x_1)$$模型化， 不如使用隐变量模型$$P(x_t|x_{t-1},\cdots, x_1) \approx P(x_t |h_{t-1})$$
* 其中$$h_{t-1}$$是_隐状态_（hidden state）， 也称为_隐藏变量_（hidden variable）， 它存储了到时间步$$t-1$$的序列信息。 通常，我们可以基于当前输入$$x_t$$和先前隐状态$$h_{t-1}$$ 来计算时间步$$t$$处的任何时间的隐状态：$$h_{t-1} = f(x_t, h_{t-1})$$
* 对于函数$$f$$，隐变量模型不是近似值。 毕竟$$h_t$$是可以仅仅存储到目前为止观察到的所有数据， 然而这样的操作可能会使计算和存储的代价都变得昂贵。

### 无隐状态的神经网络





### &#x20;有隐状态的循环神经网络





### &#x20;基于循环神经网络的字符级语言模型
