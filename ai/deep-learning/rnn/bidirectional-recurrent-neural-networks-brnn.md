# Bidirectional Recurrent Neural Networks(BRNN)







* 在Transformer模型之前，大多数最先进的NLP系统都依赖于诸如LSTM、门控循环单元（GRU）等门控RNN模型，并在此基础上增加了注意力机制。Transformer正是在注意力机制的基础上构建的，但其没有使用RNN结构，这表明仅依靠注意力机制就能在性能上比肩加上了注意力机制的RNN模型。
