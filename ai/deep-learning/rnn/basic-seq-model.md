# Basic Seq Model

#### Seq Model

* 其中，用$$x_t$$表示价格，即在_时间步_（time step） $$t \in \mathbb{Z}^{+}$$时，观察到的价格$$x_t$$。 请注意，$$t$$对于本文中的序列通常是离散的，并在整数或其子集上变化。 假设一个交易员想在$$t$$日的股市中表现良好，于是通过以下途径预测$$x_t$$：
* $$x_t \sim P(x_t | x_{t-1}, \cdots, x_1)$$

#### Autoregressive model(AR)

* 第一种策略，假设在现实情况下相当长的序列 $$x_{t-1}, \cdots, x_1$$可能是不必要的， 因此我们只需要满足某个长度为$$\tau$$的时间跨度， 即使用观测序列$$x_{t-1}, \cdots, x_{t-\tau}$$。 当下获得的最直接的好处就是参数的数量总是不变的， 至少在$$t > \tau$$时如此，这就使我们能够训练一个上面提及的深度网络。 这种模型被称为_自回归模型_（autoregressive models）， 因为它们是对自己执行回归。
* 第二种策略， 是保留一些对过去观测的总结$$h_t$$， 并且同时更新预测$$\hat{x_t}$$和总结$$h_t$$。 这就产生了基于$$\hat{x_t} = P(x_t | h_t)$$估计$$x_t$$， 以及公式$$h_t = g(h_{t-1}, x_{t-1})$$更新的模型。 由于$$h_t$$从未被观测到，这类模型也被称为 _隐变量自回归模型_（latent autoregressive models）。
* 这两种情况都有一个显而易见的问题：如何生成训练数据？ 一个经典方法是使用历史观测来预测下一个未来观测。 显然，我们并不指望时间会停滞不前。
*   然而，一个常见的假设是虽然特定值$$x_t$$可能会改变， 但是序列本身的动力学不会改变。 这样的假设是合理的，因为新的动力学一定受新的数据影响， 而我们不可能用目前所掌握的数据来预测新的动力学。 统计学家称不变的动力学为_静止的_（stationary）。 因此，整个序列的估计值都将通过以下的方式获得：

    $$P(x_1, \cdots, x_{T}) = \Pi_{t= 1}^{T}(x_t|x_{t-1}, \cdots, x_1)$$

#### Markov Model

* 我们使用$$x_{t-1}, \cdots, x_{t-\tau}$$ 而不是$$x_{t-1},\cdots, x_1$$来估计$$x_t$$。 只要这种是近似精确的，我们就说序列满足_马尔可夫条件_（Markov condition）。 特别是，如果$$\tau = 1$$，得到一个 _一阶马尔可夫模型_（first-order Markov model
* 用$$P(x_{t+1} | x_{t-1}) = \sum_{x_t} P(x_{t +1}|x_{t})P(x_t|x_{t-1})$$&#x20;

#### Causality

* you cannot inverse time



\
