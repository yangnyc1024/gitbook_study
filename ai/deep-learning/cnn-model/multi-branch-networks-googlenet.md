# Multi-Branch Networks(GoogLeNet)

* &#x20;GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进。 这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题。 毕竟，以前流行的网络使用小到$$1×1$$，大到$$11×11$$的卷积核。
* d2l的一个观点是，有时使用不同大小的卷积核组合是有利的。



#### Inception块

* 在GoogLeNet中，基本的卷积块被称为_Inception块_（Inception block）。这很可能得名于电影《盗梦空间》（Inception），因为电影中的一句话“我们需要走得更深”（“We need to go deeper”）。

<figure><img src="../../.gitbook/assets/Screenshot 2024-02-05 at 3.24.22 PM.png" alt="" width="375"><figcaption></figcaption></figure>

* Inception块由四条并行路径组成。 前三条路径使用窗口大小为$$1×1$$、$$3×3$$和$$5×5$$的卷积层，从不同空间大小中提取信息。 中间的两条路径在输入上执行$$1×1$$卷积，以减少通道数，从而降低模型的复杂性。 第四条路径使用$$3×3$$最大汇聚层，然后使用$$1×1$$卷积层来改变通道数。
* 这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。
* 那么为什么GoogLeNet这个网络如此有效呢？ 首先我们考虑一下滤波器（filter）的组合，它们可以用各种滤波器尺寸探索图像，这意味着不同大小的滤波器可以有效地识别不同范围的图像细节。 同时，我们可以为不同的滤波器分配不同数量的参数。

#### GoogleLeNet模型

* GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值。Inception块之间的最大汇聚层可降低维度。 第一个模块类似于AlexNet和LeNet，Inception块的组合从VGG继承，全局平均汇聚层避免了在最后使用全连接层。
*

    <figure><img src="../../.gitbook/assets/Screenshot 2024-02-05 at 3.25.31 PM.png" alt="" width="179"><figcaption></figcaption></figure>
* 我们逐一实现GoogLeNet的每个模块。
  * 第一个模块使用64个通道、$$7×7$$卷积层。
  * 第二个模块使用两个卷积层：第一个卷积层是64个通道、$$1×1$$卷积层；第二个卷积层使用将通道数量增加三倍的$$3×3$$卷积层。 这对应于Inception块中的第二条路径。
  * 第三个模块串联两个完整的Inception块。&#x20;
    * 第一个Inception块的输出通道数为$$64+128+32+32=256$$，四个路径之间的输出通道数量比为$$64:128:32:32=2:4:1:1$$。
    * &#x20;第二个和第三个路径首先将输入通道的数量分别减少到$$96/192=1/2$$和$$16/192=1/12$$，然后连接第二个卷积层。第二个Inception块的输出通道数增加到$$128+192+96+64=480$$，四个路径之间的输出通道数量比为$$128:192:96:64=4:6:3:2$$。&#x20;
    * 第二条和第三条路径首先将输入通道的数量分别减少到$$128/256=1/2$$和$$32/256=1/8$$。
  * 第四模块更加复杂， 它串联了5个Inception块，其
    * 输出通道数分别是$$192+208+48+64=512$$、$$160+224+64+64=512$$、$$128+256+64+64=512$$、$$112+288+64+64=528$$和$$256+320+128+128=832$$。 这些路径的通道数分配和第三模块中的类似，首先是含$$3×3$$卷积层的第二条路径输出最多通道，其次是仅含$$1×1$$卷积层的第一条路径，之后是含$$5×5$$卷积层的第三条路径和含$$3×3$$最大汇聚层的第四条路径。 其中第二、第三条路径都会先按比例减小通道数。 这些比例在各个Inception块中都略有不同。
  * 第五模块包含输出通道数为$$256+320+128+128=832$$和$$384+384+128+128=1024$$的两个Inception块。&#x20;
    * 其中每条路径通道数的分配思路和第三、第四模块中的一致，只是在具体数值上有所不同。 需要注意的是，第五模块的后面紧跟输出层，该模块同NiN一样使用全局平均汇聚层，将每个通道的高和宽变成1。 最后我们将输出变成二维数组，再接上一个输出个数为标签类别数的全连接层。
  * GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层）串联起来。其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。
  * GoogLeNet和它的后继者们一度是ImageNet上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度。
