# Perceptron and Activation Function

## Perceptron

<figure><img src="../../.gitbook/assets/Screenshot 2024-09-18 at 7.05.17 PM.png" alt=""><figcaption></figcaption></figure>

## One hidden layer

<figure><img src="../../.gitbook/assets/Screenshot 2024-09-18 at 7.05.51 PM.png" alt="" width="375"><figcaption></figcaption></figure>

<figure><img src="../../.gitbook/assets/Screenshot 2024-09-18 at 7.06.19 PM.png" alt="" width="375"><figcaption></figcaption></figure>



<figure><img src="../../.gitbook/assets/Screenshot 2024-09-18 at 7.06.39 PM.png" alt="" width="364"><figcaption></figcaption></figure>

## Activation function

激活函数的特点：非线性，可微性，单调性

#### Sigmod

#### Tanh

#### ReLU

## 输出结构Softmax

* 用于概率输出or输出结果
* 将多个神经元的输出，映射到$$(0,1)$$区间，可以当成是概率来理解，从而进行多分类

